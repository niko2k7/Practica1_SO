# Pr√°ctica 1 ‚Äì SO - Procesos y comunicaci√≥n entre procesos

<br>
<img src="https://www.pngkey.com/png/detail/268-2688228_universidad-nacional-colombia-logo.png" width="230" alt="Logo Universidad Nacional de Colombia">
UNIVERSIDAD NACIONAL DE COLOMBIA
<br>
Sistemas Operativos  
2016707 ‚Äì Grupo 2
<br><br>
Autores:  

* Nicol√°s Aguirre Vel√°squez ([niaguirrev@unal.edu.co](mailto:niaguirrev@unal.edu.co))
* Ever Nicol√°s Mu√±oz Cort√©s ([evmunoz@unal.edu.co](mailto:evmunoz@unal.edu.co))
* Fabi√°n David Mora Mart√≠nez ([fmoram@unal.edu.co](mailto:fmoram@unal.edu.co))

Docente: **Cesar Augusto Pedraza Bonilla**

---

## Contenido

* [1. Estructura del Proyecto](#1-estructura-del-proyecto)

  * [1.2 Estructura del Dataset](#12-estructura-del-dataset)
  * [1.3 Criterios de B√∫squeda](#13-criterios-de-b√∫squeda)
  * [1.4 Funci√≥n Hash y Manejo de Colisiones](#14-funci√≥n-hash-y-manejo-de-colisiones)
* [2. Ejecuci√≥n Local](#2-ejecuci√≥n-local)
* [3. Instrucciones de Uso](#3-instrucciones-de-uso)

---

## 1. Estructura del Proyecto

```txt
.
‚îú‚îÄ‚îÄ DataSet
‚îÇ   ‚îú‚îÄ‚îÄ all_movies_expanded.csv        # Dataset expandido (4.6M filas, ~1.3 GB)
‚îÇ   ‚îî‚îÄ‚îÄ hash_index.bin                 # Archivo binario con la tabla hash generada
‚îú‚îÄ‚îÄ README.md                          # Este archivo de documentaci√≥n
‚îú‚îÄ‚îÄ Makefile                           # Archivo para compilaci√≥n de los programas
‚îú‚îÄ‚îÄ murmurHash.c                       # Implementaci√≥n de la funci√≥n MurmurHash2 (32 bits)
‚îú‚îÄ‚îÄ definitions.h                      # Cabecera con estructuras, constantes, etc.
‚îú‚îÄ‚îÄ index_builder                      # Binario compilado para crear el √≠ndice hash
‚îú‚îÄ‚îÄ index_builder.c                    # C√≥digo fuente que construye el √≠ndice hash
‚îú‚îÄ‚îÄ search_process                     # Binario de proceso que realiza b√∫squedas
‚îú‚îÄ‚îÄ search_process.c                   # L√≥gica del proceso de b√∫squeda
‚îú‚îÄ‚îÄ ui_process                         # Binario de la interfaz de usuario
‚îî‚îÄ‚îÄ ui_process.c                       # Interfaz que gestiona la interacci√≥n con el usuario
```
Dataset obtenido desde la [API de TheMovieDB](https://developer.themoviedb.org/).

---

### 1.2 Estructura del Dataset

Los campos principales del dataset son:

| Campo              | Descripci√≥n                                                              |
| ------------------ | ------------------------------------------------------------------------ |
| **id**             | Identificador √∫nico de la pel√≠cula.                                      |
| **title**          | T√≠tulo de la pel√≠cula (utilizado como clave principal en las b√∫squedas). |
| **original_title** | T√≠tulo original en su idioma de origen.                                  |
| **tagline**        | Frase promocional o lema de la pel√≠cula.                                 |
| **overview**       | Sinopsis breve o resumen de la trama.                                    |
| **year**           | A√±o de lanzamiento.                                                      |
| **director**       | Director de la pel√≠cula.                                                 |
| **runtime**        | Duraci√≥n (en minutos).                                                   |
| **genres**         | Lista de g√©neros asociados a la pel√≠cula.                                |
| **vote_average**   | Promedio de votos de los usuarios.                                       |
| **vote_count**     | N√∫mero total de votos registrados.                                       |


El dataset original obtenido desde la API de TheMovieDB conten√≠a 577,848 pel√≠culas √∫nicas registradas entre los a√±os 1900 y 2025, con un tama√±o aproximado de 182 MB.
Con el fin de ampliar el volumen de datos y realizar pruebas de rendimiento sobre un dataset de mayor tama√±o, con ayuda de una IA se desarroll√≥ un script en Python que gener√≥ un dataset expandido aplicando transformaciones controladas sobre los t√≠tulos:

Duplicaci√≥n inversa: cada pel√≠cula fue duplicada invirtiendo el nombre de su t√≠tulo, manteniendo el resto de los campos sin modificaciones.

Inversi√≥n parcial: se dividi√≥ cada t√≠tulo en dos mitades, invirtiendo su orden y conservando los dem√°s atributos intactos.

Reordenamiento de palabras: las palabras de cada t√≠tulo fueron intercambiadas aleatoriamente para generar nuevas combinaciones v√°lidas.

Tras estas etapas, el dataset resultante alcanz√≥ 4,622,784 registros, con un peso final de aproximadamente 1.3 GB, conservando la coherencia estructural de los datos originales.

**Tama√±o final del dataset:** 4,622,784 filas (~1.3 GB)<br>
**Campo de indexaci√≥n:** `title` (15 caracteres normalizados)<br>
**Funci√≥n hash:** MurmurHash2 ‚Äì 32 bits<br>
**Manejo de colisiones:** Encadenamiento din√°mico en archivo binario<br>
**Tipo de comunicaci√≥n entre procesos:** Memoria compartida<br>

---

### 1.3 Criterios de B√∫squeda

El campo utilizado para las b√∫squedas fue **`title`**, ya que es el atributo m√°s representativo y distintivo para identificar una pel√≠cula.
Se toman **los primeros 15 caracteres del t√≠tulo**, convertidos a min√∫sculas, como clave de hashing.
Esto permite mantener una clave consistente y corta, manteniendo un n√∫mero de colisiones decente y mejorando el rendimiento de b√∫squeda.

Ejemplo:

```
"The Matrix" ‚Üí "the matrix"
"Fast And Furious" ‚Üí "fast and furiou"
```

De esta forma, t√≠tulos similares o con peque√±as variaciones no generan hash completamente diferentes, ayudando a una b√∫squeda m√°s eficiente.

---

### 1.4 Funci√≥n Hash y Manejo de Colisiones

Se emple√≥ la funci√≥n **MurmurHash2 (32 bits)** con el algoritmo original, debido a su alta uniformidad de dispersi√≥n y velocidad.
El hash resultante se utiliza para indexar cada pel√≠cula dentro de una **tabla hash almacenada en un archivo binario** (`hash_index.bin`).

#### üîπ Estrategia de colisiones:

Cuando varias pel√≠culas comparten el mismo hash:

1. Si la posici√≥n est√° libre, se inserta directamente.
2. Si ya existe una entrada, se crea una nueva al final del archivo binario.
3. El registro original actualiza su puntero `next` para apuntar al nuevo.
4. Si ese nuevo tambi√©n tiene colisi√≥n, se repite el proceso, formando una **cadena enlazada de colisiones en disco**.

De esta forma, nunca se sobrescriben registros y todas las entradas se mantienen accesibles mediante recorrido de la cadena.

---

## 2. Ejecuci√≥n Local

1. Clonar el repositorio:

   ```bash
   git clone https://github.com/niko2k7/Practica1_SO.git
   ```
2. Compilar los archivos:

   ```bash
   make
   ```
3. Crear el √≠ndice hash:

   ```bash
   ./index_builder
   ```
4. Ejecutar los procesos:

   ```bash
   ./ui_process
   ./search_process
   ```

---

## 3. Instrucciones de Uso

* Al ejecutar `ui_process`, el sistema inicia el proceso de la interfaz.
* Al ejecutar `search_process`, el sistema inicia el proceso de b√∫squeda y se queda en espera.
* El usuario ingresa un t√≠tulo de pel√≠cula al seleccionar la opci√≥n 1 en el proceso de la interfaz.
* El usuario selecciona la opci√≥n 2 para empezar la b√∫squeda y comunicar ambos procesos.
* El proceso de b√∫squeda localiza su posici√≥n en el √≠ndice hash.
* Se muestra la informaci√≥n completa si se encuentra, o un mensaje de no coincidencia (NA).
* Se puede repetir el proceso, o seleccionar la opci√≥n 3 para salir.

---

> *Proyecto desarrollado como pr√°ctica de manejo de procesos, memoria compartida y estructuras de datos aplicadas a sistemas operativos.*
